#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=4
#SBATCH --job-name=LICO_training_imagenet
#SBATCH --ntasks=1
#SBATCH --time=30:00:00
#SBATCH --output=output/LICO_training_imagenet_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

# activate the environment
source activate fact2024

#Run something like this:
#main.py --seed 1 --arch resnet50 --epochs 100 --batch-size 8
#--data C:/Users/Mikhail/Datasets/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC
#--dataset imagenet --lr 0.03 --training-method LICO --workers 2 --context_position end

# Run this as
# sbatch train_model_imagenet.job LICO resnet18 1 4 <WANDB_API_KEY>

# Positional args
training_method=$1 # LICO or baseline
arch=$2 # resnet18 or resnet50
seed=$3
num_devices=$4
WANDB_API_KEY=$5

export WANDB_API_KEY=$WANDB_API_KEY

# Run 1: Visual prompting CLIP on CIFAR-10 with standard text prompt
code_dir="$HOME/uva_fact_2024"

# Standard constants
dataset="imagenet"
#data="$code_dir/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC"
data="/scratch-nvme/ml-datasets/imagenet/ILSVRC/Data/CLS-LOC"
epochs=100
batch_size=128
workers=8
lr=0.03

alpha=10.0
beta=1.0

context_position="end"


## Copy the val data to the scratch-node (very fast brr)
train_root="$data"
val_root="/scratch-shared/$USER"

data_dest=$val_root

# Create the destination directory if it doesn't exist
mkdir -p "$val_root"

# Check if the destination directory exists and is not empty
if [ -d "$data_dest" ] && [ "$(ls -A $data_dest)" ]; then
    echo "Data already exists at $data_dest. Skipping copy."
else
    echo "Copying dataset $data/val to $data_dest"
    rsync --info=progress2 -r "$data/val" "$data_dest"

    # Fix structure of val set
    echo "Fixing val set dir structure"
    cd "$data_dest/val" || exit
    wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash
fi

# Run the experiment
echo "Running experiment on $dataset with $training_method and batch size $batch_size and seed $seed"
cd "$code_dir" || exit
python $code_dir/main.py \
    --dataset $dataset \
    --train_dir "$train_root/train" \
    --val_dir "$val_root/val" \
    --arch $arch \
    --epochs $epochs \
    --training-method $training_method \
    --alpha $alpha \
    --beta $beta \
    --seed $seed \
    --workers $workers \
    --lr $lr \
    --devices "$num_devices" \
    --context_position $context_position
