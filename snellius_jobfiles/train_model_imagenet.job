#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=4
#SBATCH --job-name=LICO_training_imagenet
#SBATCH --ntasks=1
#SBATCH --time=40:00:00
#SBATCH --output=output/LICO_training_imagenet_%A.out

module purge
module load 2022
module load Anaconda3/2022.05

# activate the environment
source activate fact2024

# Example
# cd uva_fact_2024
# source .env && sbatch --time=25:00:00 --gpus=1 snellius_jobfiles/train_model_imagenet.job training_method=baseline arch=resnet18 seed=1 num_devices=1 alpha=0 beta=0 epochs=90 batch_size=256 workers=8 lr=0.1

# Parse named arguments
for arg in "$@"
do
    key=$(echo "$arg" | cut -f1 -d=)
    value=$(echo "$arg" | cut -f2 -d=)
    eval "${key}='${value}'"
done

# ========= Vars to set =========
#training_method # LICO or baseline
#arch # resnet18 or resnet50
#seed= # 1
#num_devices= # 1 or 4
#alpha= # 10 or 0
#beta= # 1 or 0
#epochs= # 90
# effective_batch_size = batch_size * num_devices
#batch_size= # 64
#workers= # 8
#lr= # 0.1

VARS=(training_method arch seed num_devices alpha beta epochs batch_size workers lr gradient_clip_val)
for var in "${VARS[@]}"; do
  if [ -z "${!var}" ]; then
    echo "Error: $var is not set or is empty."
    exit 1
  else
    echo "$var=${!var}"
  fi
done
# ========= Vars to set =========



code_dir="$HOME/uva_fact_2024"
dataset="imagenet"
data="/scratch-nvme/ml-datasets/imagenet/ILSVRC/Data/CLS-LOC"

# Wandb API key
set -o allexport
source "$code_dir/.env"
set -o allexport
#alpha=10.0
#beta=1.0

context_position="end"

## Copy the val data to the scratch-shared
train_root="$data"
val_root="/scratch-shared/$USER"

data_dest=$val_root

# Create the destination directory if it doesn't exist
mkdir -p "$val_root"

# Check if the destination directory exists and is not empty
if [ -d "$data_dest" ] && [ "$(ls -A $data_dest)" ]; then
    echo "Data already exists at $data_dest. Skipping copy."
else
    echo "Copying dataset $data/val to $data_dest"
    rsync --info=progress2 -r "$data/val" "$data_dest"

    # Fix structure of val set
    echo "Fixing val set dir structure"
    cd "$data_dest/val" || exit
    wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash
fi

# Run the experiment
echo "Running experiment on $dataset with $training_method and batch size $batch_size and seed $seed"
cd "$code_dir" || exit
python "$code_dir/main.py" \
    --dataset $dataset \
    --train_dir "$train_root/train" \
    --val_dir "$val_root/val" \
    --arch "$arch" \
    --epochs "$epochs" \
    --training-method "$training_method" \
    --alpha "$alpha" \
    --beta "$beta" \
    --seed "$seed" \
    --workers "$workers" \
    --lr "$lr" \
    --batch-size "$batch_size" \
    --devices "$num_devices" \
    --context_position "$context_position" \
    --gradient_clip_val "$gradient_clip_val"
